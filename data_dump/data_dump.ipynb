{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cfab550-86d1-4217-a98d-8d8216e23396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jeannetaoliviasantoso/final_project/data_dump\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b694faad-359c-4f4c-92a2-9a7d99c5d562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sa\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "423fb4ef-c0e2-4821-ba95-787e540c7083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import sqlalchemy as sa\n",
    "\n",
    "def connect_to_db(username, password, host, port, database):\n",
    "\n",
    "    try:\n",
    "        # Create connection URL\n",
    "        connection_url = sa.URL.create(\n",
    "            \"postgresql+psycopg2\",\n",
    "            username=username,\n",
    "            password=password,\n",
    "            host=host,\n",
    "            port=port,\n",
    "            database=database\n",
    "        )\n",
    "\n",
    "        # Create and return the SQLAlchemy engine\n",
    "        engine = create_engine(connection_url)\n",
    "        print(\"Database connection established successfully\")\n",
    "        return engine\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to the database: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_multiple_csvs_to_db(engine, csv_file_paths, table_names, if_exists_option='append', sleep_time=30):\n",
    "\n",
    "    if len(csv_file_paths) != len(table_names):\n",
    "        print(\"Error: The number of CSV file paths must match the number of table names.\")\n",
    "        return\n",
    "\n",
    "    for csv_path, table_name in zip(csv_file_paths, table_names):\n",
    "        try:\n",
    "            # Load the data from the current CSV file\n",
    "            data = pd.read_csv(csv_path)\n",
    "\n",
    "            # Write the data to the database\n",
    "            data.to_sql(table_name, engine, if_exists=if_exists_option, index=False)\n",
    "            print(f\"Data from '{csv_path}' inserted successfully into table '{table_name}'\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while processing '{csv_path}': {e}\")\n",
    "        \n",
    "        # Pause for the specified sleep time\n",
    "        print(f\"Waiting for {sleep_time} seconds before processing the next file...\")\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "    print(\"Finish the job.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2c0a118-57eb-4c8f-943c-dd05bd0ccc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection established successfully\n"
     ]
    }
   ],
   "source": [
    "# Database connection details\n",
    "username = \n",
    "password = \n",
    "host = \n",
    "port = \n",
    "database = \n",
    "\n",
    "# Create the database engine\n",
    "engine = connect_to_db(username, password, host, port, database)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c0f97ff-c45e-429e-90d0-ab7a11a0bd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_paths = [\n",
    "    \"csv_file/data_management_payroll_update.csv\",\n",
    "    \"csv_file/data_performance_management_update.csv\",\n",
    "]\n",
    "\n",
    "table_names = [\n",
    "    \"data_payroll_champy\",\n",
    "    \"data_performance_champy\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21060815-29ef-42c8-bbe5-035a753ed949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from 'csv_file/data_management_payroll_update.csv' inserted successfully into table 'data_payroll_champy'\n",
      "Waiting for 30 seconds before processing the next file...\n",
      "Data from 'csv_file/data_performance_management_update.csv' inserted successfully into table 'data_performance_champy'\n",
      "Waiting for 30 seconds before processing the next file...\n",
      "Finish the job.\n"
     ]
    }
   ],
   "source": [
    "# Ensure the database engine is created\n",
    "if engine is not None:\n",
    "    load_multiple_csvs_to_db(engine, csv_file_paths, table_names, sleep_time=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffa7755-f8ff-4b11-81dd-66bafef90fce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfad546-ac28-4e72-95bd-f3614f98c471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f15b726-2893-462d-b5d7-3ef940f1d369",
   "metadata": {},
   "source": [
    "USING pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a90e2133-b9a7-4e41-a516-55d2ca2f91d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "\n",
    "# MySQL connection details\n",
    "username = \n",
    "password = \n",
    "host = \n",
    "port = \n",
    "database = \n",
    "\n",
    "# Establish a direct connection to MySQL\n",
    "connection = pymysql.connect(\n",
    "    host=host,\n",
    "    user=username,\n",
    "    password=password,\n",
    "    database=database,\n",
    "    port=port\n",
    ")\n",
    "\n",
    "# Load data from CSV\n",
    "csv_path = \"csv_file/data_management_payroll_update.csv\"\n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "# Table name\n",
    "table_name = \"data_payroll_champy\"\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Dynamically generate CREATE TABLE SQL based on the columns in the CSV\n",
    "columns = ', '.join([f\"{col} VARCHAR(255)\" for col in data.columns])  # Assume all columns are VARCHAR for simplicity\n",
    "create_table_sql = f\"CREATE TABLE IF NOT EXISTS {table_name} ({columns});\"\n",
    "\n",
    "# Execute the CREATE TABLE query\n",
    "cursor.execute(create_table_sql)\n",
    "\n",
    "# Insert data into MySQL\n",
    "for i, row in data.iterrows():\n",
    "    sql = f\"INSERT INTO {table_name} ({', '.join(data.columns)}) VALUES ({', '.join(['%s'] * len(row))})\"\n",
    "    cursor.execute(sql, tuple(row))\n",
    "\n",
    "# Commit the transaction and close the connection\n",
    "connection.commit()\n",
    "cursor.close()\n",
    "connection.close()\n",
    "\n",
    "print(\"Data inserted successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec630e3-3790-4a33-8063-ac99b803c466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4266af15-cb1b-402b-838e-7bb7f1f8aa60",
   "metadata": {},
   "source": [
    "USING sqlalchemy mysql "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fac931dc-aa39-404d-8f76-f81c50c9f4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mysql-connector-python in /Users/jeannetaoliviasantoso/anaconda3/lib/python3.12/site-packages (9.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mysql-connector-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e764381-2372-4f15-b23a-d81d9c363343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "\n",
    "# Database connection details\n",
    "username = \n",
    "password = \n",
    "host = \n",
    "port = \n",
    "database = \n",
    "\n",
    "\n",
    "# URL encode the password to handle special characters\n",
    "password = quote_plus(\"ftde03!@#\")\n",
    "\n",
    "# Using the MySQL connection string\n",
    "connection_url = f\"mysql+mysqlconnector://{username}:{password}@{host}:{port}/{database}\"\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine = create_engine(connection_url)\n",
    "\n",
    "# Load data from CSV\n",
    "csv_path = \"csv_file/data_management_payroll_update.csv\"\n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "# Table name\n",
    "table_name = \"data_payroll_champy\"\n",
    "\n",
    "# Write data to the database using the engine\n",
    "try:\n",
    "    # pandas `to_sql` automatically handles the connection through SQLAlchemy\n",
    "    data.to_sql(table_name, engine, if_exists='append', index=False)\n",
    "    print(\"Data inserted successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fe4de4-9194-43e1-923a-83385ae4138c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67aee6b-d09f-49d3-ab03-2f994338d8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec073a79-7546-4f52-8a0d-32f455d9988b",
   "metadata": {},
   "source": [
    "MYSQL data dump function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d1d0180-ab9a-4415-9047-7998a22b1582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import quote_plus\n",
    "import time\n",
    "\n",
    "# Function to create a connection to MySQL\n",
    "def create_mysql_connection(username, password, host, port, database):\n",
    "    # URL encode the password to handle special characters\n",
    "    encoded_password = quote_plus(password)\n",
    "\n",
    "    # Create the engine with the encoded password\n",
    "    engine = create_engine(f\"mysql+mysqlconnector://{username}:{encoded_password}@{host}:{port}/{database}\")\n",
    "    \n",
    "    # Test the connection\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            print(\"Successfully connected to MySQL!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to MySQL: {e}\")\n",
    "        raise\n",
    "    return engine\n",
    "\n",
    "# Function to load multiple CSV files into corresponding MySQL tables\n",
    "def load_csv_to_mysql(csv_files, table_names, username, password, host, port, database, sleep_time=30):\n",
    "    # Create the MySQL connection engine\n",
    "    engine = create_mysql_connection(username, password, host, port, database)\n",
    "    \n",
    "    # Ensure that the number of CSV files matches the number of table names\n",
    "    if len(csv_files) != len(table_names):\n",
    "        print(\"Error: The number of CSV files does not match the number of table names.\")\n",
    "        return\n",
    "    \n",
    "    for csv_path, table_name in zip(csv_files, table_names):\n",
    "        try:\n",
    "            # Load data from CSV\n",
    "            data = pd.read_csv(csv_path)\n",
    "\n",
    "            # Write data to the database using the engine\n",
    "            data.to_sql(table_name, engine, if_exists='append', index=False)\n",
    "            print(f\"Data from {csv_path} inserted successfully into {table_name}.\")\n",
    "\n",
    "            # Sleep for the specified amount of time\n",
    "            print(f\"Waiting for {sleep_time} seconds before proceeding to the next file...\")\n",
    "            time.sleep(sleep_time)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while processing {csv_path}: {e}\")\n",
    "            \n",
    "    print(\"Finish the job.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48e41c9d-b4e2-4cf7-ae62-acec3d462edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to MySQL!\n",
      "Data from csv_file/data_training_development_update.csv inserted successfully into data_training_champy.\n",
      "Waiting for 30 seconds before proceeding to the next file...\n",
      "Finish the job.\n"
     ]
    }
   ],
   "source": [
    "# Usage Example\n",
    "# Database connection details\n",
    "username = \n",
    "password = \n",
    "host = \n",
    "port = \n",
    "database = \n",
    "\n",
    "csv_files = [\n",
    "    \"csv_file/data_training_development_update.csv\"\n",
    "]\n",
    "\n",
    "table_names = [\n",
    "    \"data_training_champy\"\n",
    "]\n",
    "\n",
    "# Call the function to load data from CSV to MySQL\n",
    "load_csv_to_mysql(csv_files, table_names, username, password, host, port, database, sleep_time=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e6b256-eb87-4bb1-8c6e-678bdfd0cb71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b8dfa4-09f1-4ce2-9694-76f5930fe400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b2d85a-3210-4c43-b7ef-53f632fac6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad92867-d98e-49c9-afba-99e72b32dc85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a0fa88-f66c-4a37-a5d0-1b14a0ddbd6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0da6739-5f2c-4652-bb7f-397cbd8a0e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_paths_read = [\n",
    "    \"csv_file/data_management_payroll_update.csv\",\n",
    "    \"csv_file/data_performance_management_update.csv\",\n",
    "    \"csv_file/data_training_development_update.csv\",\n",
    "    \"csv_file/data_recruitment_selection_update.csv\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15213523-0984-4bbc-9473-6f04a8242bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = 'csv_file/data_management_payroll_update.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f335f64-3895-4941-8c28-f817810b1fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_management_payroll_update'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save[save.find('/') + 1:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d8bcea-916b-45b7-8850-4daee85ff222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cec408e-6f63-4efa-abc1-2c84c5ea5275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70af86dd-c3a1-455b-92b9-84ddb8f5cc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File name: data_management_payroll_update\n",
      "['EmployeeID', 'Name', 'Gender', 'Age', 'Department', 'Position', 'Salary', 'OvertimePay', 'PaymentDate']\n",
      "\n",
      "File name: data_performance_management_update\n",
      "['EmployeeID', 'Name', 'ReviewPeriod', 'Rating', 'Comments']\n",
      "\n",
      "File name: data_training_development_update\n",
      "['EmployeeID', 'Name', 'TrainingProgram', 'StartDate', 'EndDate', 'Status']\n",
      "\n",
      "File name: data_recruitment_selection_update\n",
      "['CandidateID', 'Name', 'Gender', 'Age', 'Position', 'ApplicationDate', 'Status', 'InterviewDate', 'OfferStatus']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for r in csv_file_paths_read:\n",
    "    df = pd.read_csv(r)\n",
    "    print(f\"File name: {r[r.find('/') + 1:-4]}\")\n",
    "    print(df.columns.tolist())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934512a4-30a1-4ded-bd3b-83c030c60b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
